# Stream Processing for Network Attack Detection

A real-time stream processing system for network traffic analysis and attack detection using Kafka, machine learning models, and microservices architecture.

## ğŸ—ï¸ Architecture Overview

This system implements a complete stream processing pipeline for network security:

```
Data Ingestion â†’ Kafka Producer â†’ ML Processing â†’ Attack Detection â†’ Results Storage
     â†“              â†“                 â†“              â†“              â†“
  FastAPI      Raw Data Topic    NLP Pipeline   Processed Topic   MongoDB
```

## ğŸš€ Key Features

- **Real-time Stream Processing**: Kafka-based streaming with configurable processing modes
- **ML-powered Attack Detection**: Uses Hugging Face transformers for network traffic classification
- **Flexible Processing Modes**: 
  - Pure streaming (message-by-message)
  - Micro-batch processing (configurable batch size and timeout)
- **Multi-Engine Support**: PyTorch and ONNX Runtime for model inference
- **Comprehensive Monitoring**: Prometheus metrics and Langfuse observability
- **Scalable Storage**: MongoDB for processed results
- **Production Ready**: Logging, error handling, and performance optimization

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **Python 3.11**
- **Apache Kafka** - Stream processing platform
- **FastAPI** - Web framework for data ingestion API
- **MongoDB** - Document database for results storage

### Machine Learning
- **PyTorch** - Deep learning framework
- **Transformers** (Hugging Face) - Pre-trained models
- **ONNX Runtime** - Optimized inference engine
- **Pandas** - Data manipulation

### Monitoring & Observability
- **Prometheus** - Metrics collection
- **Langfuse** - ML observability and tracing
- **Custom Logging** - Application-level logging

## ğŸ“ Project Structure

```
stream_processing/
â”œâ”€â”€ api.py                      # FastAPI endpoints for data ingestion
â”œâ”€â”€ app.py                      # Main application entry point
â”œâ”€â”€ data_test_stream/          # Test datasets
â”œâ”€â”€ db/                        # Database components
â”‚   â”œâ”€â”€ connection.py          # MongoDB connection handler
â”‚   â””â”€â”€ storage.py             # Data storage service
â”œâ”€â”€ logging/                   # Logging and monitoring
â”‚   â””â”€â”€ logging_monitor.py     # Application logger with tracing
â”œâ”€â”€ modules/                   # Kafka components
â”‚   â”œâ”€â”€ kafka_consumer.py      # Kafka consumer utilities
â”‚   â”œâ”€â”€ kafka_producer.py      # Kafka producer wrapper
â”‚   â””â”€â”€ kafka_producer_service.py # Producer service layer
â”œâ”€â”€ nlp/                       # Machine learning pipeline
â”‚   â”œâ”€â”€ data_loader.py         # Data preprocessing
â”‚   â”œâ”€â”€ pipeline.py            # Main inference pipeline
â”‚   â””â”€â”€ engine/                # Model loading engines
â”œâ”€â”€ setting/                   # Configuration management
â”‚   â”œâ”€â”€ config.py              # Environment-based settings
â”‚   â”œâ”€â”€ common.py              # Common enums and constants
â”‚   â””â”€â”€ constants.py           # Application constants
â””â”€â”€ utils/                     # Utility functions
    â””â”€â”€ huggingface_util.py    # Model downloading utilities
```

## âš™ï¸ Configuration

Create a `.env` file with the following variables:

```env
# Model Configuration
LOCAL_DIR=/path/to/local/models
HUGGINGFACE_REPO_ID=your-model-repo

# Kafka Configuration  
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
RAW_DATA_TOPIC=raw_network_data
PROCESSED_ATTACK_DATA_TOPIC=processed_attack_data

# MongoDB Configuration
MONGO_URI=mongodb://localhost:27017
DB_NAME=network_security
RESULTS_ATTACK_COLLECTION=attack_results

# Langfuse Configuration (Optional)
LANGFUSE_HOST=https://your-langfuse-instance
LANGFUSE_SECRET_KEY=your-secret-key
LANGFUSE_PUBLIC_KEY=your-public-key
```

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.11**
2. **Apache Kafka** running on localhost:9092
3. **MongoDB** running on localhost:27017

### Installation

1. Clone the repository:
```bash
git clone https://github.com/TrongNV2003/stream-processing.git
cd stream-processing
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

### Running the System

1. **Start the main application:**
```bash
./run.sh
# or
python -m stream_processing.app
```

2. **Ingest data via API:**
```bash
curl -X POST "http://localhost:8000/ingest"
```

## ğŸ”§ System Components

### 1. Data Ingestion (FastAPI)
- RESTful API for data ingestion
- Chunks large files for efficient processing
- Async background task processing

### 2. Stream Processing (Kafka)
- **Producer**: Sends network traffic data to Kafka topics
- **Consumer**: Processes data in real-time or micro-batches
- **Topics**: 
  - `raw_network_data`: Incoming network traffic
  - `processed_attack_data`: ML inference results

### 3. ML Pipeline (NLP)
- **Feature Engineering**: Converts network metrics to text context
- **Model Inference**: Uses transformer models for classification
- **Attack Detection**: Identifies malicious network patterns
- **Batch Processing**: Configurable batch size and timeout

### 4. Data Storage (MongoDB)
- Stores processed results with metadata
- Includes prediction confidence and timing information
- Supports queries for analysis and reporting

## ğŸ“Š Monitoring & Metrics

### Prometheus Metrics
- `processed_messages_total`: Total messages processed
- `processing_latency_seconds`: Processing time distribution
- `detected_attacks_total`: Number of attacks detected

### Langfuse Tracing
- End-to-end request tracing
- Model performance monitoring
- Input/output logging for debugging

## ğŸ” Processing Modes

### Pure Streaming
```python
processor = NetworkInference(
    processing_mode="streaming",
    # Process one message at a time
)
```

### Micro-batch Processing
```python
processor = NetworkInference(
    processing_mode="micro_batch",
    batch_size=8,           # Messages per batch
    batch_timeout=0.1       # Max wait time (seconds)
)
```

## ğŸ›¡ï¸ Network Attack Detection

The system analyzes network traffic features including:
- **Protocol information**
- **Flow duration and packet counts**
- **Byte and packet rates**
- **Flag counts (SYN, RST, PSH, ACK)**
- **Statistical measures** (mean, max, ratios)

### Supported Attack Types
The model can detect various network attacks (configured via `id2label` in model config):
- DDoS attacks
- Port scanning
- Intrusion attempts
- Malicious traffic patterns

## ğŸš€ Performance Optimizations

- **GPU Acceleration**: Automatic CUDA detection for faster inference
- **ONNX Runtime**: Optimized model execution
- **Batch Processing**: Reduces per-message overhead
- **Async Operations**: Non-blocking I/O operations
- **Connection Pooling**: Efficient database connections

## ğŸ§ª Testing

Use the provided test dataset:
```bash
# Test data is located in data_test_stream/test_dataset.csv
curl -X POST "http://localhost:8000/ingest"
```

## ğŸ“ˆ Scaling Considerations

- **Horizontal Scaling**: Deploy multiple consumer instances
- **Kafka Partitioning**: Distribute load across partitions  
- **Model Optimization**: Use ONNX for production deployments
- **Database Sharding**: Scale MongoDB for large datasets
- **Load Balancing**: Use multiple API instances

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For issues and questions:
- Create an issue on GitHub
- Check the logs in `logs/app.log`
- Monitor Prometheus metrics for system health

## ğŸ”— Related Projects

- [Apache Kafka](https://kafka.apache.org/)
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [MongoDB](https://www.mongodb.com/)